[
  {
    "objectID": "example_RNAseq_analysis.html",
    "href": "example_RNAseq_analysis.html",
    "title": "Differential Gene Expression",
    "section": "",
    "text": "This document outlines the steps to perform a differential expression analysis at the gene-level, with explanations of code, methods and best practices throughout. You may notice that this file has the .qmd extension, specifying it as a Quarto document. This can be considered the “next generation” of R Markdown. At it’s core, Quarto works the same way as R Markdown. However, Quarto provides some additional functionality that can be useful. Code chunks and text from existing R Markdown documents can be transferred to Quarto documents and should simply just work.\nQuarto/R Markdown provides an authoring framework for data science. In a single document, the user can incorporate both code and paragraphs of text. When generating the report, the code gets executed and its output is displayed in the report. This enables analyses that can easily be turned into high quality reports to share with an audience. Importantly, this facilitates reproducibility, and frequent rendering of the report is encouraged to ensure code runs from top to bottom. It is even possible to insert inline code, allowing the values of variables to be reported within a paragraph of text. For example, let’s use a code chunk to generate a random number sampled from a normal distribution with mean of 0 and standard deviation of 1, and assign it to the variable random_normal:\n\n\nCode\nrandom_normal &lt;- rnorm(n = 1, mean = 0, sd = 1)\n\n\nWe can now use this variable to report our result: The randomly sampled number was -1.0419085. You will notice each time you generate the report from this document the number will change.\n\n\n\n\n\n\nTip\n\n\n\nCode chunks require a header, which is displayed in its most simple form as {r}. I have assigned a label to the above code chunk, which is best practice but also optional. Naming code chunks is handy for debugging, and incredibly useful when the code outputs a plot. Quarto generates the plot as a png file with a filename corresponding to the chunk label, and saves it in a convenient location. This saves the hassle of writing further code to save a figure, and it can easily be shared with colleagues, used for a presentation, etc. Chunk headers won’t be visible in the final report, but instead control how that particular code chunk acts.\n\n\nThere is plenty more you can do with Quarto and R Markdown. Follow these links to the Quarto and R Markdown documentation.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#installing-bioconductor-and-r-packages",
    "href": "example_RNAseq_analysis.html#installing-bioconductor-and-r-packages",
    "title": "Differential Gene Expression",
    "section": "Installing Bioconductor and R packages",
    "text": "Installing Bioconductor and R packages\nBioconductor is an open source project that provides tools and software packages for the analysis and interpretation of high-throughput genomic data. If Bioconductor is not already installed on your system, or is an older version, follow the installation instructions on the Bioconductor website. At the time of updating this document, Bioconductor was in version 3.21 of the release cycle, which can be installed as follows:\n\n\nCode\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(version = \"3.21\")\n\n\nIf Bioconductor was successfully installed, you will have access to the BiocManager package. Using BiocManager is the recommended way to install any further packages.\n\n\n\n\n\n\nNote\n\n\n\nIn the above code chunk I have added a chunk option to its header (eval=FALSE). This specifies that that code chunk will not be executed when a report is generated.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#loading-libraries",
    "href": "example_RNAseq_analysis.html#loading-libraries",
    "title": "Differential Gene Expression",
    "section": "Loading libraries",
    "text": "Loading libraries\nThe first step in any analysis is to load packages into the environment, allowing easy access to functions required for the analysis. Attempting to load a package will error if the package is not already installed on your system. For any packages that require installation, we can use the RStudio console to do so, e.g. BiocManager::install(\"tidyverse\"). You can install all the required packages for this document with the following code:\n\n\nCode\nBiocManager::install(c(\n    \"tidyverse\", \"magrittr\", \"here\", \"kableExtra\", \"RColorBrewer\", \"ggpubr\",\n    \"scales\", \"AnnotationHub\", \"ggrepel\", \"ggtext\", \"glue\", \"pander\",\n    \"reactable\", \"htmltools\", \"edgeR\", \"limma\", \"tximport\", \"pheatmap\"\n))\n\n\n\n\nCode\n## Common packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(here)\nlibrary(kableExtra)\nlibrary(RColorBrewer)\nlibrary(ggpubr)\nlibrary(scales)\nlibrary(AnnotationHub)\nlibrary(ggrepel)\nlibrary(ggtext)\nlibrary(glue)\nlibrary(pander)\nlibrary(reactable)\nlibrary(htmltools)\n## Document-specific packages\nlibrary(edgeR)\nlibrary(limma)\nlibrary(tximport)\nlibrary(pheatmap)\n\n\nNow we set up any further options as desired for the document.\n\n\nCode\n## Set the ggplot2 theme\ntheme_set(theme_bw())\n## Allow markdown formatting of title and axis labels with the ggtext package\ntheme_update(\n    title = element_markdown(),\n    axis.title = element_markdown(),\n    legend.title = element_markdown()\n)",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#loading-count-data",
    "href": "example_RNAseq_analysis.html#loading-count-data",
    "title": "Example RNA-seq Analysis",
    "section": "Loading count data",
    "text": "Loading count data\nGene-level count data was previously generated by featureCounts using the Snakemake workflow. Normally I do not push featureCounts output files to GitHub, as they often border the file size limit of 50MB. Instead I transfer them manually from the Phoenix HPC to my local device. This means the count data is not backed up, but, the Snakemake code still is. Snakemake ensures reproducibility and can always be used to generate the same file from raw data. This is the approach I take for any large files; as long as we have access to the raw data, our code should be written such that it can consistently produce the same outputs. For the sake of this example the data is included in the repository.\nLet’s load the featureCounts output and apply some modifications to achieve a nicely formatted data.frame.\n\n\nCode\ncounts &lt;- read_tsv(\n    here(\"smk-rnaseq-counts-1.2.2/results/featureCounts/reverse/all.featureCounts\"),\n    comment = \"#\"\n) %&gt;%\n    dplyr::select(-c(Chr, Start, End, Strand, Length)) %&gt;%\n    set_colnames(basename(colnames(.))) %&gt;%\n    set_colnames(str_remove(colnames(.), \"\\\\.bam\")) %&gt;%\n    as.data.frame() %&gt;%\n    column_to_rownames(\"Geneid\") %&gt;%\n    .[,colnames(.) %in% meta$sample]\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe dot/period, ., is commonly used within a chunk of code chained together with magrittr pipe operator, %&gt;%. When a pipe operator is used, the object preceding the pipe is always used as the first argument of the following function. There is also another type of pipe operator, the base pipe, |&gt;. This is a newer implementation which acts almost identically and can be accessed without loading additional packages. The magrittr pipe, however, still has an advantage over the base pipe in that the preceding object can be specified as . for additional arguments in the same function, as seen in the above code.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom here onwards we set up our analysis to perform differential expression (DE) testing using the edgeR package. Another commonly used package for DE analysis is DESeq2. While the overall goal and methodology is conceptually similar between the two approaches, this is where some steps may diverge, particular in the use of R objects and functions. There is no correct choice between the two packages, they are both incredibly robust approaches that perform as such. The edgeR User’s Guide is filled with extensive information and use cases for the methodology implemented in the following sections.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#filtering",
    "href": "example_RNAseq_analysis.html#filtering",
    "title": "Example RNA-seq Analysis",
    "section": "Filtering",
    "text": "Filtering\nedgeR utilises a DGEList object to store data throughout the analysis. A DGEList is very similar to a base R list and can be manipulated as such. The main elements that comprise a DGEList is a counts matrix (as loaded above) and a samples data.frame containing sample metadata. Here we also append agenes element containing gene feature annotations. Once the DGEList is initialised, we remove genes with low expression.\n\n\nCode\nmin_cpm &lt;- 1\nmin_samps &lt;- meta %&gt;%\n    group_by(group) %&gt;%\n    summarise(n = n()) %&gt;%\n    pull(n) %&gt;%\n    min()\ndge_samples &lt;- tibble(sample = colnames(counts)) %&gt;%\n    left_join(meta) %&gt;%\n    mutate(group = group)\ndge_genes &lt;- genes %&gt;%\n    as.data.frame() %&gt;%\n    .[rownames(counts),] %&gt;%\n    dplyr::select(chr = seqnames, everything()) %&gt;%\n    mutate(chr = fct_relevel(chr, primary_chrs))\ndge_unfilt &lt;- DGEList(\n    counts,\n    samples = dge_samples,\n    genes = dge_genes\n) %&gt;%\n    normLibSizes()\n## Keep genes that satisfy minumum CPM threshold\nkeep_genes &lt;- rowSums(cpm(dge_unfilt$counts) &gt;= min_cpm) &gt;= min_samps\ndge_list &lt;- dge_unfilt[keep_genes, , keep.lib.sizes=FALSE] %&gt;%\n    normLibSizes()\n\n\nGenes with low counts across all libraries provide little evidence for differential expression. The discreteness of these counts also interferes with downstream statistical approximations. We therefore choose to retain genes for downstream analysis if they have greater than 1 counts per million (CPM) in at least 3 samples. A minimum of 3 samples was chosen because this is the number of samples in the smallest experimental group, meaning that each remaining gene must have assigned reads detected in at least one experimental group. Filtering is performed independently of which sample belongs to which group so that no bias is introduced.\n13,299 genes remain for further analysis from an initial 63,140 genes. Library sizes range from 62,079,836 to 83,439,168.\nThe outcomes of filtering can be visualised by plotting expression density plots before and after the removal of weakly expressed genes.\n\n\nCode\ndens_unfilt &lt;- cpm(dge_unfilt, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"Before filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Type\"\n    )\ndens_filt &lt;- cpm(dge_list, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"After filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Type\"\n    )\nggarrange(dens_unfilt, dens_filt, common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nExpression density plots for all samples before and after filtering. Samples are coloured by group.\n\n\n\n\nHere we can see that prior to filtering, the majority of genes in each sample had very low (or no) counts. The fact that all our samples follow a similar distribution is an indication of good quality data. In particular, we expect samples belonging to the same group to follow a similar distribution.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#design-matrix",
    "href": "example_RNAseq_analysis.html#design-matrix",
    "title": "Differential Gene Expression",
    "section": "Design matrix",
    "text": "Design matrix\nThe design matrix is a critical component of statistical modelling approaches to determine differential expression. It defines the experimental design and specifies how the variables in a study relate to the observed gene expression data. I find this paper an incredibly useful resource to guide the construction of both simple and complex design matrices.\n\n\nCode\ndesign &lt;- model.matrix(~0 + group, data = dge_list$samples) %&gt;%\n    set_colnames(str_remove(colnames(.), \"group\"))\n\n\nHere we have parameterised the design matrix as a means model for DE testing. A means model lacks an intercept term, meaning we have to specify contrasts to calculate the difference between mutant and control samples. While this requires an extra step, I personally find this setup more intuitive and flexible. One may also use a mean-reference model to achieve the same eventual outcome, whereby the control group is generally specified as the intercept representing baseline expression and therefore allowing direct calculation of the difference between mutant and control. Refer to the above paper to understand the difference in parameterisation and how either choice can achieve the same end result.\nTo visualise the design matrix, we can plot a binary heatmap.\n\n\nCode\npheatmap(\n    design[meta$sample,],\n    cluster_cols = FALSE,\n    cluster_rows = FALSE,\n    color = c(\"white\", \"grey50\"),\n    annotation_row = dge_list$samples[\"group\"],\n    annotation_colors = list(group = pal_group),\n    angle_col = \"315\",\n    legend = FALSE\n)\n\n\n\n\n\nVisualisation of the means model design matrix. White represents a value of 0 and grey represents a value of 1.\n\n\n\n\n\n\n\n\n\n\nExpand for a mean-reference model example\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nHere we have to ensure R knows the group column of our dge_list$samples object is a categorical variable, by setting it as a factor object. Additionally, the control group is required to be first level of the factor, such that it forms the intercept. We specified this explicitly when initially loading the metadata.\n\n\n\n\nCode\ndesign_2 &lt;- model.matrix(~group, data = dge_list$samples) %&gt;%\n    set_colnames(str_remove(colnames(.), \"group\"))\n\n\n\n\nCode\npheatmap(\n    design_2[meta$sample,],\n    cluster_cols = FALSE,\n    cluster_rows = FALSE,\n    color = c(\"white\", \"grey50\"),\n    annotation_row = dge_list$samples[\"group\"],\n    annotation_colors = list(group = pal_group),\n    angle_col = \"315\",\n    legend = FALSE\n)\n\n\n\n\n\nVisualisation of the mean-reference model design matrix. White represents a value of 0 and grey represents a value of 1.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#contrast-matrix",
    "href": "example_RNAseq_analysis.html#contrast-matrix",
    "title": "Differential Gene Expression",
    "section": "Contrast matrix",
    "text": "Contrast matrix\nNext we construct our desired contrasts.\n\n\nCode\ncontrasts &lt;- makeContrasts(\n    upf1_vs_control = UPF1 - Control,\n    levels = colnames(design)\n)\npander(contrasts)\n\n\n\n\n\n\n\n\n\n \nupf1_vs_control\n\n\n\n\nControl\n-1\n\n\nUPF1\n1\n\n\n\n\n\nWe specify the contrast matrix such that the control group expression is subtracted from the mutant group expression. This means our results will be reported from the perspective of our group of interest, i.e. the mutant samples.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#fitting-the-model",
    "href": "example_RNAseq_analysis.html#fitting-the-model",
    "title": "Differential Gene Expression",
    "section": "Fitting the model",
    "text": "Fitting the model\nHere’s where the smart stuff happens. I’ll attempt to provide a simplified summary of the methodology. For a proper explanation, see the references in section 1.2 of the edgeR User’s Guide.\nThe first step is to estimate the dispersion (variability) in the data with the estimateDisp() function. This estimates three types of dispersion:\n\nCommon dispersion: The mean dispersion across all genes.\nTagwise dispersion: A gene-specific dispersion value, accounting for the fact that some genes may have more variability than others.\nTrended dispersion: The mean dispersion across all genes with similar abundance, which can be plotted as a smooth curve showing the relationship between mean expression and dispersion.\n\nThe second step is to fit a quasi-likelihood (QL) negative binomial generalized log-linear model (GLM) to the read counts for each gene with the glmQLFit() function. It also computes a QL dispersion, which reflects the biological variability in counts and the uncertainty in the dispersion estimate, making it more robust to outliers or small sample sizes compared to basic GLMs. It uses empirical Bayes methods to “squeeze” the estimates for genes with unreliable dispersion estimates (e.g. due to low counts) towards the overall trend, resulting in more stable estimates. This provides better control of the false discovery rate (FDR) in RNA-seq data.\nThe third step performs hypothesis testing to determine whether the expression of a gene is significantly different between the experimental groups with the glmQLFTest() function. This uses the QL F-test to produce a test statistic from which a p-value can be computed.\n\n\nCode\ndisp &lt;- estimateDisp(dge_list, design)\nfit &lt;- glmQLFit(disp)\ntt &lt;- glmQLFTest(fit, contrast = contrasts[,\"upf1_vs_control\"]) %&gt;%\n    topTags(n = Inf) %&gt;%\n    .[[\"table\"]] %&gt;%\n    as_tibble() %&gt;%\n    arrange(PValue) %&gt;%\n    dplyr::select(\n        gene_id, gene_name, logFC, logCPM, PValue, FDR, everything()\n    ) %&gt;%\n    mutate(\n        DE = ifelse(FDR &lt; 0.05, TRUE, FALSE),\n        direction = case_when(\n            logFC &lt;= 0 & DE ~ \"Downregulated\",\n            logFC &gt;= 0 & DE ~ \"Upregulated\",\n            !DE ~ \"Non-siginificant\"\n        )\n    )\n\n\nWe now have gene-level assigned p-values, as well as other relevant stats in our tt object. Before we take a look at the results, let’s check some plots to ensure everything looks as expected for RNA-seq data.\nA mean-variance plot can be used to explore the relationship between the mean expression levels of genes and their variance. This helps to assess the assumptions of edgeR’s methodology, which models gene expression using the negative binomial distribution. Here we are looking to evaluate the model fit. If our data points follow the negative binomial line closely, this indicates that the model has effectively captured the mean-variance relationship.\n\n\nCode\nplotMeanVar(\n    disp, show.raw.vars = TRUE, show.tagwise.vars = TRUE, NBline = TRUE\n)\n\n\n\n\n\nMean-variance trend. The black line indicates a typical poisson distribution, while the blue line indicates the negative binomial fit. The grey points indicate raw variances, which are the pooled variances of the counts from each sample, divided by the effective library size. The tagwise variances are indicated as blue points, and the red X’s represent the binned common dispersions.\n\n\n\n\nThe plot clearly illustrates the overdispersion inherent to RNA-seq data. Overall, the data closely follows the fitted negative binomial line, meaning we have established an appropriate model.\nThe dispersion estimates can be viewed in a BCV plot. This allows us to assess data quality by identifying expected (or unexpected) patterns in variability. It also helps to validate the model, confirming the estimated dispersion trends align with the expected relationship between expression and variability.\n\n\nCode\nplotBCV(disp)\n\n\n\n\n\n\n\n\n\nA typical BCV plot shows that variation is higher at low mean expression levels. This is because genes with low counts are more influenced by sampling noise. For very highly expressed genes, the BCV flattens and stabilises, often reaching a minimum value because biological variability dominates over technical noise. The above plot is a great example of what we expect to see from a BCV plot.\nThe QL dispersions are also useful to visualise. It complements the BCV plot by focusing on the uncertainty in both the dispersion and mean-variance relationship.\n\n\nCode\nplotQLDisp(fit)\n\n\n\n\n\n\n\n\n\nA QL dispersion plot can be interpreted similarly to that of a BCV plot. Additionally, we can see how the dispersion estimates are “squeezed” towards the overall trend in variability.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#results",
    "href": "example_RNAseq_analysis.html#results",
    "title": "Differential Gene Expression",
    "section": "Results",
    "text": "Results\nThe reactable package is a great package for producing interactive tables in R. It is highly customisable, which also means it can require a reasonable amount of code. However, your collaborators will appreciate nicely formatted results with the ability to easily navigate through the list of genes. In the following code chunk we define some functions that can be re-used to plot reactable tables with less repetition of code.\n\n\nCode\nlb_reactable &lt;- function(\n        tbl, highlight = TRUE, striped = TRUE, compact = TRUE,\n        wrap = FALSE, resizable = TRUE, searchable = TRUE,\n        style = list(fontFamily = \"Calibri, sans-serif\"), ...\n){\n    reactable(\n        tbl,\n        highlight = highlight, striped = striped, compact = compact,\n        wrap = wrap, resizable = TRUE, searchable = TRUE,\n        style = style, ...\n    )\n}\nreact_numeric &lt;- function(format, digits = 2){\n    colDef(cell = function(val, ind, col_name){\n        formatC(val, digits = digits, format = format)\n    })\n}\n\n\nOur tt object holds the results from our DE analysis ordered by p-value, such that the most significant differentially expressed genes exist at the top of the table. We tested 12,329 genes for differential expression, which is a lot. Rendering the entire set of results in our report will impact its file size, so let’s just take the top 1000.\n\n\nCode\n## browsable() allows us to render this html table interactively in RStudio\nbrowsable(\n    ## Use a tagList to include multiple html elements\n    tagList(\n        tags$caption(glue(\n            \"The top 1000 most significant genes \",\n            \"from differential expression analysis. \",\n            \"{sum(tt$DE)} genes were determined to be differentially \",\n            \"expressed (FDR &lt; 0.05).\"\n        )),\n        ## Use our previously defined function to create the table\n        lb_reactable(\n            tt %&gt;%\n                dplyr::slice(1:1000) %&gt;%\n                dplyr::select(\n                    gene_id, gene_name, chromosome = chr,\n                    logFC, logCPM, PValue, FDR, DE\n                ),\n            elementId = \"tt\",\n            defaultColDef = colDef(\n                align = \"left\",\n                minWidth = 80\n            ),\n            ## Numeric column formatting\n            columns = list(\n                logFC = react_numeric(\"f\"),\n                logCPM = react_numeric(\"f\"),\n                PValue = react_numeric(\"e\"),\n                FDR = react_numeric(\"e\")\n            )\n        ),\n        ## Button to download results as CSV file\n        tags$button(\n            tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n            onclick = \"Reactable.downloadDataCSV('tt', 'de_results.csv')\"\n        )\n    )\n)\n\n\nThe top 1000 most significant genes from differential expression analysis. 0 genes were determined to be differentially expressed (FDR &lt; 0.05).\n\n\n\n\nDownload as CSV\n\n\n\nIt is usual practice in bioinformatics that a logarithm of base 2 is implied where this information is omitted. Therefore, the logFC and logCPM columns indicate the log2 fold change and counts per million respectively. For example, a gene with logFC = 1 indicates a 2-fold increase in expression in mutant samples relative to controls. Similary, a gene with logCPM = 4 indicates an average expression of 16 CPM across all samples.\nWe classify genes as differentially expressed based on the criteria of a False Discovery Rate (FDR)-adjusted p-value less than 0.05. FDR-adjusted p-values are where raw p-values (PValue column) have been subject to Benjamini-Hochberg correction for multiple hypothesis testing. This is required because we have individually tested the null hypothesis, \\(H_0\\), that there is no differential expression between mutant and control samples for all 12,329 genes in our dataset.\nWe only have 6 genes determined to be differentially expressed in this analysis. This may suggest that the sample groups are not very different. However, in this scenario it is more likely that we are lacking statistical power due to having only 3 samples in the mutant group. 3 samples is the minimum number required to capture biological variability, with at least 5 samples being recommended. Unfortunately, when working with patient data these kind of scenarios are often unavoidable, but we can still make use of our results in downstream analyses, such as Gene Set Enrichment Analysis (GSEA).",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#visualising-the-results",
    "href": "example_RNAseq_analysis.html#visualising-the-results",
    "title": "Differential Gene Expression",
    "section": "Visualising the results",
    "text": "Visualising the results\n\nVolcano plot\nVolcano plots are used to visualise the relationship between statistical significance and magnitude of change in gene expression. We plot logFC on the x-axis and -log10(p) on the y-axis, such that the most significant genes are observed at the top of the plot. This helps to identify genes that are both highly significant and exhibit large fold changes. We can also assess the symmetry of the plot to determine in there is an approximately equal number of upregulated and downregulated genes. If an unsymmetrical representation is unexpectedly observed, it may indicate an issue with data quality.\n\n\nCode\ntt %&gt;%\n    bind_rows() %&gt;%\n    arrange(DE) %&gt;%\n    ggplot(aes(logFC, -log10(PValue), colour = direction)) +\n    geom_point(size = 2, alpha = 0.4) +\n    geom_text_repel(\n        aes(label = gene_name),\n        size = 3,\n        data = . %&gt;% dplyr::filter(DE),\n        show.legend = FALSE\n    ) +\n    scale_colour_manual(values = c(\n        \"Upregulated\" = \"darkblue\", \"Downregulated\" = \"darkred\")\n    ) +\n    labs(y = \"-log~10~(*p*)\", colour = \"Direction\") +\n    theme(legend.position = \"none\")\n\n\n\n\n\nVolcano plot from differential expression testing. Upregulated DE genes are coloured blue, downregulated DE genes are coloured red.\n\n\n\n\n\n\nMA plot\nMA plots allow us to visualise the relationship between the magnitude of gene expression change (M) and average expression levels (A). We plot logCPM on the x-axis, and logFC on the y-axis. MA plots are useful for checking whether TMM normalisation has successfully balanced the expression estimates across samples. A properly normalised MA plot should display points mostly centered around y = 0.\n\n\nCode\ntt %&gt;%\n    bind_rows() %&gt;%\n    arrange(DE) %&gt;%\n    ggplot(aes(logCPM, logFC, colour = direction)) +\n    geom_point(size = 2, alpha = 0.4) +\n    geom_text_repel(\n        aes(label = gene_name),\n        size = 3,\n        data = . %&gt;% dplyr::filter(DE),\n        show.legend = FALSE\n    ) +\n    geom_smooth(se = FALSE, colour = \"black\") +\n    scale_colour_manual(values = c(\n        \"Upregulated\" = \"darkblue\", \"Downregulated\" = \"darkred\")\n    ) +\n    labs(colour = \"Direction\") +\n    theme(legend.position = \"none\")\n\n\n\n\n\nMA plot from differential expression testing. Upregulated DE genes are coloured blue, downregulated DE genes are coloured red.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Example RNA-seq Analysis",
    "section": "",
    "text": "Back to top",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#filtering-count-data",
    "href": "example_RNAseq_analysis.html#filtering-count-data",
    "title": "Differential Gene Expression",
    "section": "Filtering count data",
    "text": "Filtering count data\nedgeR utilises a DGEList object to store data throughout the analysis. A DGEList is very similar to a base R list and can be manipulated as such. The main elements that comprise a DGEList is a counts matrix (as loaded above) and a samples data.frame containing sample metadata. Here we also append agenes element containing gene feature annotations. Once the DGEList is initialised, we remove genes with low expression.\n\n\nCode\nmin_cpm &lt;- 1\nmin_samps &lt;- meta %&gt;%\n    group_by(group) %&gt;%\n    summarise(n = n()) %&gt;%\n    pull(n) %&gt;%\n    min()\ndge_samples &lt;- tibble(sample = colnames(counts)) %&gt;%\n    left_join(meta) %&gt;%\n    mutate(group = group)\ndge_genes &lt;- genes %&gt;%\n    as.data.frame() %&gt;%\n    .[rownames(counts),] %&gt;%\n    dplyr::select(chr = seqnames, everything()) %&gt;%\n    mutate(chr = fct_relevel(chr, primary_chrs))\ndge_unfilt &lt;- DGEList(\n    counts,\n    samples = dge_samples,\n    genes = dge_genes\n) %&gt;%\n    normLibSizes()\n## Keep genes that satisfy minumum CPM threshold in X samples\nkeep_genes &lt;- rowSums(cpm(dge_unfilt$counts) &gt;= min_cpm) &gt;= min_samps\ndge_list &lt;- dge_unfilt[keep_genes, , keep.lib.sizes=FALSE] %&gt;%\n    normLibSizes()\n\n\nGenes with low counts across all libraries provide little evidence for differential expression. The discreteness of these counts also interferes with downstream statistical approximations. We therefore choose to retain genes for downstream analysis if they have greater than 1 counts per million (CPM) in at least 3 samples. A minimum of 3 samples was chosen because this is the number of samples in the smallest experimental group, meaning that each remaining gene must have assigned reads detected in at least one experimental group. Filtering is performed independently of which sample belongs to which group so that no bias is introduced.\n12,329 genes remain for further analysis from an initial 34,284 genes. Library sizes range from 75,735,636 to 108,477,439.\nThe outcomes of filtering can be visualised by plotting expression density plots before and after the removal of weakly expressed genes.\n\n\nCode\ndens_unfilt &lt;- cpm(dge_unfilt, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"Before filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Group\"\n    )\ndens_filt &lt;- cpm(dge_list, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"After filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Group\"\n    )\nggarrange(dens_unfilt, dens_filt, common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nExpression density plots for all samples before and after filtering. Samples are coloured by group.\n\n\n\n\nHere we can see that prior to filtering, the majority of genes counted in each sample had very low (or no) counts. The fact that all our samples follow a similar distribution is an indication of good quality data. In particular, we expect samples belonging to the same group to follow a similar distribution.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#importing-count-data",
    "href": "example_RNAseq_analysis.html#importing-count-data",
    "title": "Differential Gene Expression",
    "section": "Importing count data",
    "text": "Importing count data\nTwo common choices for generating counts from RNA-seq data are Salmon or featureCounts.\nSalmon is a lightweight, alignment-free (or quasi-mapping) tool that directly quantifies transcript-level abundance from FASTQ files using a pre-built transcriptome index. It corrects for sequence- and bias-related factors like GC content and positional bias, and produces transcript-level estimates such as TPM, as well as estimated counts. Salmon is especially efficient and well-suited for workflows that require fast transcript-level resolution, or when downstream tools like tximport are used to aggregate transcript-level estimates into gene-level counts.\nfeatureCounts is an alignment-based tool that quantifies reads by counting how many align to genomic features such as genes or exons. It relies on a pre-aligned BAM file, typically produced by aligners like STAR or HISAT2, and uses a reference annotation to assign reads to features. Because it operates at the gene- or exon-level on genome-aligned reads, featureCounts is widely used in traditional RNA-seq pipelines, particularly when accurate splice-aware alignment is important. It produces raw counts suitable for differential expression analysis with tools like edgeR and DESEq2.\nCounts files can be large so I tend not to push these to GitHub, instead opting to transfer them manually from the Phoenix HPC to my local device. This means the count data is not tracked, but, the Snakemake code still is. Snakemake ensures reproducibility and can always be used to generate the same file from raw data. This is the approach I take for any large files; as long as we have access to the raw data, our code should be written such that it can consistently produce the same outputs. For the purpose of this example the count data is included in the repository.\nExamples of importing count data from both Salmon and featureCounts is provided below, just click the appropriate tab! Note, however, we’ll use Salmon counts for the remainder of this document.\n\nfeatureCountsSalmon\n\n\n\n\nCode\ncounts &lt;- read_tsv(\n    here(\"smk-rnaseq-counts-1.2.7/results/featureCounts/reverse/all.featureCounts\"),\n    comment = \"#\"\n) %&gt;%\n    dplyr::select(-c(Chr, Start, End, Strand, Length)) %&gt;%\n    set_colnames(basename(colnames(.))) %&gt;%\n    set_colnames(str_remove(colnames(.), \"\\\\.bam\")) %&gt;%\n    as.data.frame() %&gt;%\n    column_to_rownames(\"Geneid\")\n## Subset for genes on primary chromosomes & samples in metadata\ncounts &lt;- counts[\n    rownames(counts) %in% genes$gene_id,\n    colnames(counts) %in% meta$sample\n]\n\n\n\n\n\n\nCode\ntxi &lt;- list.files(\n    here(\"smk-rnaseq-counts-1.2.7/results/salmon\"),\n    pattern = \"quant.sf\", recursive = TRUE, full.names = TRUE\n) %&gt;%\n    set_names(basename(dirname(.))) %&gt;%\n    tximport(\n        type = \"salmon\", tx2gene = tx2gene, ignoreTxVersion = TRUE,\n        countsFromAbundance = \"lengthScaledTPM\"\n    )\ncounts &lt;- txi$counts\n## Subset for genes on primary chromosomes & samples in metadata\ncounts &lt;- counts[\n    rownames(counts) %in% genes$gene_id,\n    colnames(counts) %in% meta$sample\n]\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe dot/period, ., is commonly used within a chunk of code chained together with magrittr pipe operator, %&gt;%. When a pipe operator is used, the object preceding the pipe is always used as the first argument of the following function. There is also another type of pipe operator, the base pipe, |&gt;. This is a newer implementation which acts almost identically and can be accessed without loading additional packages. The magrittr pipe, however, still has an advantage over the base pipe in that the preceding object can be specified as . for additional arguments in the same function, as seen in the above code.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom here onwards we set up our analysis to perform differential expression (DE) testing using the edgeR package. Another commonly used package for DE analysis is DESeq2. While the overall goal and methodology is conceptually similar between the two approaches, this is where some steps may diverge, particular in the use of R objects and functions. There is no correct choice between the two packages, they are both incredibly robust approaches that perform as such. The edgeR User’s Guide is filled with extensive information and use cases for the methodology implemented in the following sections.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "example_RNAseq_analysis.html#cpm-vs-tpm",
    "href": "example_RNAseq_analysis.html#cpm-vs-tpm",
    "title": "Differential Gene Expression",
    "section": "CPM vs TPM",
    "text": "CPM vs TPM\nYou have probably heard Counts Per Million (CPM) and Transcripts Per Million (TPM) used to describe normalised expression units in RNA-seq analysis. These terms are sometimes used interchangeably, but they actually differ in what they normalise for. CPM adjusts raw read counts for sequencing depth by scaling to the total number of reads in each sample, allowing for comparison of expression levels across samples. TPM goes a step further by also adjusting for effective transcript length, enabling better comparisons across both genes and samples within a dataset. This distinction is important because longer transcripts tend to accumulate more reads simply due to their length, which TPM corrects for. For further explanation, see: What the FPKM? A review of RNA-Seq expression units.\nIn the example using Salmon, you may have noticed the argument countsFromAbundance = \"lengthScaledTPM\" passed to tximport. This setting produces pseudo-counts: values that begin as TPMs but are scaled back to count-like units using both transcript length and library size information. Although they originate from normalised values, these pseudo-counts are structured to resemble raw counts in scale and statistical properties, making them suitable for downstream differential expression analysis methods which expect count-like input.\nImportantly these pseudo-counts have already been adjusted for effective transcript length. This eliminates a major confounder in RNA-seq analysis, the correlation between expression and transcript length. Eliminating this correlation is particularly important when aggregating transcript-level estimates to the gene level, where differential transcript usage can otherwise introduce misleading abundance signals. As a result, we can use CPM values from pseudo-counts for filtering and exploratory visualisation.",
    "crumbs": [
      "DGE"
    ]
  },
  {
    "objectID": "dge.html",
    "href": "dge.html",
    "title": "Differential Gene Expression",
    "section": "",
    "text": "This document outlines the steps to perform a differential expression analysis at the gene-level, with explanations of code, methods and best practices throughout. You may notice that this file has the .qmd extension, specifying it as a Quarto document. This can be considered the “next generation” of R Markdown. At it’s core, Quarto works the same way as R Markdown. However, Quarto provides some additional functionality that can be useful. Code chunks and text from existing R Markdown documents can be transferred to Quarto documents and should simply just work.\nQuarto/R Markdown provides an authoring framework for data science. In a single document, the user can incorporate both code and paragraphs of text. When generating the report, the code gets executed and its output is displayed in the report. This enables analyses that can easily be turned into high quality reports to share with an audience. Importantly, this facilitates reproducibility, and frequent rendering of the report is encouraged to ensure code runs from top to bottom. It is even possible to insert inline code, allowing the values of variables to be reported within a paragraph of text. For example, let’s use a code chunk to generate a random number sampled from a normal distribution with mean of 0 and standard deviation of 1, and assign it to the variable random_normal:\n\n\nCode\nrandom_normal &lt;- rnorm(n = 1, mean = 0, sd = 1)\n\n\nWe can now use this variable to report our result: The randomly sampled number was -0.708461. You will notice each time you generate the report from this document the number will change.\n\n\n\n\n\n\nTip\n\n\n\nCode chunks require a header, which is displayed in its most simple form as {r}. I have assigned a label to the above code chunk, which is best practice but also optional. Naming code chunks is handy for debugging, and incredibly useful when the code outputs a plot. Quarto generates the plot as a png file with a filename corresponding to the chunk label, and saves it in a convenient location. This saves the hassle of writing further code to save a figure, and it can easily be shared with colleagues, used for a presentation, etc. Chunk headers won’t be visible in the final report, but instead control how that particular code chunk acts.\n\n\nThere is plenty more you can do with Quarto and R Markdown. Follow these links to the Quarto and R Markdown documentation."
  },
  {
    "objectID": "dge.html#installing-bioconductor-and-r-packages",
    "href": "dge.html#installing-bioconductor-and-r-packages",
    "title": "Differential Gene Expression",
    "section": "Installing Bioconductor and R packages",
    "text": "Installing Bioconductor and R packages\nBioconductor is an open source project that provides tools and software packages for the analysis and interpretation of high-throughput genomic data. If Bioconductor is not already installed on your system, or is an older version, follow the installation instructions on the Bioconductor website. At the time of updating this document, Bioconductor was in version 3.21 of the release cycle, which can be installed as follows:\n\n\nCode\nif (!require(\"BiocManager\", quietly = TRUE))\n    install.packages(\"BiocManager\")\nBiocManager::install(version = \"3.21\")\n\n\nIf Bioconductor was successfully installed, you will have access to the BiocManager package. Using BiocManager is the recommended way to install any further packages.\n\n\n\n\n\n\nNote\n\n\n\nIn the above code chunk I have added a chunk option to its header (eval=FALSE). This specifies that that code chunk will not be executed when a report is generated."
  },
  {
    "objectID": "dge.html#loading-libraries",
    "href": "dge.html#loading-libraries",
    "title": "Differential Gene Expression",
    "section": "Loading libraries",
    "text": "Loading libraries\nThe first step in any analysis is to load packages into the environment, allowing easy access to functions required for the analysis. Attempting to load a package will error if the package is not already installed on your system. For any packages that require installation, we can use the RStudio console to do so, e.g. BiocManager::install(\"tidyverse\"). You can install all the required packages for this document with the following code:\n\n\nCode\nBiocManager::install(c(\n    \"tidyverse\", \"magrittr\", \"here\", \"kableExtra\", \"RColorBrewer\", \"ggpubr\",\n    \"scales\", \"AnnotationHub\", \"ggrepel\", \"ggtext\", \"glue\", \"pander\",\n    \"reactable\", \"htmltools\", \"edgeR\", \"limma\", \"tximport\", \"pheatmap\"\n))\n\n\n\n\nCode\n## Common packages\nlibrary(tidyverse)\nlibrary(magrittr)\nlibrary(here)\nlibrary(kableExtra)\nlibrary(RColorBrewer)\nlibrary(ggpubr)\nlibrary(scales)\nlibrary(AnnotationHub)\nlibrary(ggrepel)\nlibrary(ggtext)\nlibrary(glue)\nlibrary(pander)\nlibrary(reactable)\nlibrary(htmltools)\n## Document-specific packages\nlibrary(edgeR)\nlibrary(limma)\nlibrary(tximport)\nlibrary(pheatmap)\n\n\nNow we set up any further options as desired for the document.\n\n\nCode\n## Set the ggplot2 theme\ntheme_set(theme_bw())\n## Allow markdown formatting of title and axis labels with the ggtext package\ntheme_update(\n    title = element_markdown(),\n    axis.title = element_markdown(),\n    legend.title = element_markdown()\n)"
  },
  {
    "objectID": "dge.html#importing-count-data",
    "href": "dge.html#importing-count-data",
    "title": "Differential Gene Expression",
    "section": "Importing count data",
    "text": "Importing count data\nTwo common choices for generating counts from RNA-seq data are Salmon or featureCounts.\nSalmon is a lightweight, alignment-free (or quasi-mapping) tool that directly quantifies transcript-level abundance from FASTQ files using a pre-built transcriptome index. It corrects for sequence- and bias-related factors like GC content and positional bias, and produces transcript-level estimates such as TPM, as well as estimated counts. Salmon is especially efficient and well-suited for workflows that require fast transcript-level resolution, or when downstream tools like tximport are used to aggregate transcript-level estimates into gene-level counts.\nfeatureCounts is an alignment-based tool that quantifies reads by counting how many align to genomic features such as genes or exons. It relies on a pre-aligned BAM file, typically produced by aligners like STAR or HISAT2, and uses a reference annotation to assign reads to features. Because it operates at the gene- or exon-level on genome-aligned reads, featureCounts is widely used in traditional RNA-seq pipelines, particularly when accurate splice-aware alignment is important. It produces raw counts suitable for differential expression analysis with tools like edgeR and DESEq2.\nCounts files can be large so I tend not to push these to GitHub, instead opting to transfer them manually from the Phoenix HPC to my local device. This means the count data is not tracked, but, the Snakemake code still is. Snakemake ensures reproducibility and can always be used to generate the same file from raw data. This is the approach I take for any large files; as long as we have access to the raw data, our code should be written such that it can consistently produce the same outputs. For the purpose of this example the count data is included in the repository.\nExamples of importing count data from both Salmon and featureCounts is provided below, just click the appropriate tab! Note, however, we’ll use Salmon counts for the remainder of this document.\n\nfeatureCountsSalmon\n\n\n\n\nCode\ncounts &lt;- read_tsv(\n    here(\"smk-rnaseq-counts-1.2.7/results/featureCounts/reverse/all.featureCounts\"),\n    comment = \"#\"\n) %&gt;%\n    dplyr::select(-c(Chr, Start, End, Strand, Length)) %&gt;%\n    set_colnames(basename(colnames(.))) %&gt;%\n    set_colnames(str_remove(colnames(.), \"\\\\.bam\")) %&gt;%\n    as.data.frame() %&gt;%\n    column_to_rownames(\"Geneid\")\n## Subset for genes on primary chromosomes & samples in metadata\ncounts &lt;- counts[\n    rownames(counts) %in% genes$gene_id,\n    colnames(counts) %in% meta$sample\n]\n\n\n\n\n\n\nCode\ntxi &lt;- list.files(\n    here(\"smk-rnaseq-counts-1.2.7/results/salmon\"),\n    pattern = \"quant.sf\", recursive = TRUE, full.names = TRUE\n) %&gt;%\n    set_names(basename(dirname(.))) %&gt;%\n    tximport(\n        type = \"salmon\", tx2gene = tx2gene, ignoreTxVersion = TRUE,\n        countsFromAbundance = \"lengthScaledTPM\"\n    )\ncounts &lt;- txi$counts\n## Subset for genes on primary chromosomes & samples in metadata\ncounts &lt;- counts[\n    rownames(counts) %in% genes$gene_id,\n    colnames(counts) %in% meta$sample\n]\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nThe dot/period, ., is commonly used within a chunk of code chained together with magrittr pipe operator, %&gt;%. When a pipe operator is used, the object preceding the pipe is always used as the first argument of the following function. There is also another type of pipe operator, the base pipe, |&gt;. This is a newer implementation which acts almost identically and can be accessed without loading additional packages. The magrittr pipe, however, still has an advantage over the base pipe in that the preceding object can be specified as . for additional arguments in the same function, as seen in the above code.\n\n\n\n\n\n\n\n\nNote\n\n\n\nFrom here onwards we set up our analysis to perform differential expression (DE) testing using the edgeR package. Another commonly used package for DE analysis is DESeq2. While the overall goal and methodology is conceptually similar between the two approaches, this is where some steps may diverge, particular in the use of R objects and functions. There is no correct choice between the two packages, they are both incredibly robust approaches that perform as such. The edgeR User’s Guide is filled with extensive information and use cases for the methodology implemented in the following sections."
  },
  {
    "objectID": "dge.html#cpm-vs-tpm",
    "href": "dge.html#cpm-vs-tpm",
    "title": "Differential Gene Expression",
    "section": "CPM vs TPM",
    "text": "CPM vs TPM\nYou have probably heard Counts Per Million (CPM) and Transcripts Per Million (TPM) used to describe normalised expression units in RNA-seq analysis. These terms are sometimes used interchangeably, but they actually differ in what they normalise for. CPM adjusts raw read counts for sequencing depth by scaling to the total number of reads in each sample, allowing for comparison of expression levels across samples. TPM goes a step further by also adjusting for effective transcript length, enabling better comparisons across both genes and samples within a dataset. This distinction is important because longer transcripts tend to accumulate more reads simply due to their length, which TPM corrects for. For further explanation, see: What the FPKM? A review of RNA-Seq expression units.\nIn the example using Salmon, you may have noticed the argument countsFromAbundance = \"lengthScaledTPM\" passed to tximport. This setting produces pseudo-counts: values that begin as TPMs but are scaled back to count-like units using both transcript length and library size information. Although they originate from normalised values, these pseudo-counts are structured to resemble raw counts in scale and statistical properties, making them suitable for downstream differential expression analysis methods which expect count-like input.\nImportantly these pseudo-counts have already been adjusted for effective transcript length. This eliminates a major confounder in RNA-seq analysis, the correlation between expression and transcript length. Eliminating this correlation is particularly important when aggregating transcript-level estimates to the gene level, where differential transcript usage can otherwise introduce misleading abundance signals. As a result, we can use CPM values from pseudo-counts for filtering and exploratory visualisation."
  },
  {
    "objectID": "dge.html#filtering-count-data",
    "href": "dge.html#filtering-count-data",
    "title": "Differential Gene Expression",
    "section": "Filtering count data",
    "text": "Filtering count data\nedgeR utilises a DGEList object to store data throughout the analysis. A DGEList is very similar to a base R list and can be manipulated as such. The main elements that comprise a DGEList is a counts matrix (as loaded above) and a samples data.frame containing sample metadata. Here we also append agenes element containing gene feature annotations. Once the DGEList is initialised, we remove genes with low expression.\n\n\nCode\nmin_cpm &lt;- 1\nmin_samps &lt;- meta %&gt;%\n    group_by(group) %&gt;%\n    summarise(n = n()) %&gt;%\n    pull(n) %&gt;%\n    min()\ndge_samples &lt;- tibble(sample = colnames(counts)) %&gt;%\n    left_join(meta) %&gt;%\n    mutate(group = group)\ndge_genes &lt;- genes %&gt;%\n    as.data.frame() %&gt;%\n    .[rownames(counts),] %&gt;%\n    dplyr::select(chr = seqnames, everything()) %&gt;%\n    mutate(chr = fct_relevel(chr, primary_chrs))\ndge_unfilt &lt;- DGEList(\n    counts,\n    samples = dge_samples,\n    genes = dge_genes\n) %&gt;%\n    normLibSizes()\n## Keep genes that satisfy minumum CPM threshold in X samples\nkeep_genes &lt;- rowSums(cpm(dge_unfilt$counts) &gt;= min_cpm) &gt;= min_samps\ndge_list &lt;- dge_unfilt[keep_genes, , keep.lib.sizes=FALSE] %&gt;%\n    normLibSizes()\n\n\nGenes with low counts across all libraries provide little evidence for differential expression. The discreteness of these counts also interferes with downstream statistical approximations. We therefore choose to retain genes for downstream analysis if they have greater than 1 counts per million (CPM) in at least 3 samples. A minimum of 3 samples was chosen because this is the number of samples in the smallest experimental group, meaning that each remaining gene must have assigned reads detected in at least one experimental group. Filtering is performed independently of which sample belongs to which group so that no bias is introduced.\n12,329 genes remain for further analysis from an initial 34,284 genes. Library sizes range from 75,735,636 to 108,477,439.\nThe outcomes of filtering can be visualised by plotting expression density plots before and after the removal of weakly expressed genes.\n\n\nCode\ndens_unfilt &lt;- cpm(dge_unfilt, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"Before filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Group\"\n    )\ndens_filt &lt;- cpm(dge_list, log = TRUE) %&gt;%\n    as.data.frame() %&gt;%\n    pivot_longer(\n        cols = everything(),\n        names_to = \"sample\",\n        values_to = \"logCPM\"\n    ) %&gt;%\n    left_join(dge_list$samples) %&gt;%\n    ggplot(aes(logCPM, colour = group, group = sample)) +\n    geom_density() +\n    scale_colour_manual(values = pal_group) +\n    labs(\n        title = \"After filtering\",\n        x = \"logCPM\",\n        y = \"Density\",\n        colour = \"Group\"\n    )\nggarrange(dens_unfilt, dens_filt, common.legend = TRUE, legend = \"bottom\")\n\n\n\n\n\nExpression density plots for all samples before and after filtering. Samples are coloured by group.\n\n\n\n\nHere we can see that prior to filtering, the majority of genes counted in each sample had very low (or no) counts. The fact that all our samples follow a similar distribution is an indication of good quality data. In particular, we expect samples belonging to the same group to follow a similar distribution."
  },
  {
    "objectID": "dge.html#design-matrix",
    "href": "dge.html#design-matrix",
    "title": "Differential Gene Expression",
    "section": "Design matrix",
    "text": "Design matrix\nThe design matrix is a critical component of statistical modelling approaches to determine differential expression. It defines the experimental design and specifies how the variables in a study relate to the observed gene expression data. I find this paper an incredibly useful resource to guide the construction of both simple and complex design matrices.\n\n\nCode\ndesign &lt;- model.matrix(~0 + group, data = dge_list$samples) %&gt;%\n    set_colnames(str_remove(colnames(.), \"group\"))\n\n\nHere we have parameterised the design matrix as a means model for DE testing. A means model lacks an intercept term, meaning we have to specify contrasts to calculate the difference between mutant and control samples. While this requires an extra step, I personally find this setup more intuitive and flexible. One may also use a mean-reference model to achieve the same eventual outcome, whereby the control group is generally specified as the intercept representing baseline expression and therefore allowing direct calculation of the difference between mutant and control. Refer to the above paper to understand the difference in parameterisation and how either choice can achieve the same end result.\nTo visualise the design matrix, we can plot a binary heatmap.\n\n\nCode\npheatmap(\n    design[meta$sample,],\n    cluster_cols = FALSE,\n    cluster_rows = FALSE,\n    color = c(\"white\", \"grey50\"),\n    annotation_row = dge_list$samples[\"group\"],\n    annotation_colors = list(group = pal_group),\n    angle_col = \"315\",\n    legend = FALSE\n)\n\n\n\n\n\nVisualisation of the means model design matrix. White represents a value of 0 and grey represents a value of 1.\n\n\n\n\n\n\n\n\n\n\nExpand for a mean-reference model example\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nHere we have to ensure R knows the group column of our dge_list$samples object is a categorical variable, by setting it as a factor object. Additionally, the control group is required to be first level of the factor, such that it forms the intercept. We specified this explicitly when initially loading the metadata.\n\n\n\n\nCode\ndesign_2 &lt;- model.matrix(~group, data = dge_list$samples) %&gt;%\n    set_colnames(str_remove(colnames(.), \"group\"))\n\n\n\n\nCode\npheatmap(\n    design_2[meta$sample,],\n    cluster_cols = FALSE,\n    cluster_rows = FALSE,\n    color = c(\"white\", \"grey50\"),\n    annotation_row = dge_list$samples[\"group\"],\n    annotation_colors = list(group = pal_group),\n    angle_col = \"315\",\n    legend = FALSE\n)\n\n\n\n\n\nVisualisation of the mean-reference model design matrix. White represents a value of 0 and grey represents a value of 1."
  },
  {
    "objectID": "dge.html#contrast-matrix",
    "href": "dge.html#contrast-matrix",
    "title": "Differential Gene Expression",
    "section": "Contrast matrix",
    "text": "Contrast matrix\nNext we construct our desired contrasts.\n\n\nCode\ncontrasts &lt;- makeContrasts(\n    upf1_vs_control = UPF1 - Control,\n    levels = colnames(design)\n)\npander(contrasts)\n\n\n\n\n\n\n\n\n\n \nupf1_vs_control\n\n\n\n\nControl\n-1\n\n\nUPF1\n1\n\n\n\n\n\nWe specify the contrast matrix such that the control group expression is subtracted from the mutant group expression. This means our results will be reported from the perspective of our group of interest, i.e. the mutant samples."
  },
  {
    "objectID": "dge.html#fitting-the-model",
    "href": "dge.html#fitting-the-model",
    "title": "Differential Gene Expression",
    "section": "Fitting the model",
    "text": "Fitting the model\nHere’s where the smart stuff happens. I’ll attempt to provide a simplified summary of the methodology. For a proper explanation, see the references in section 1.2 of the edgeR User’s Guide.\nThe first step is to estimate the dispersion (variability) in the data with the estimateDisp() function. This estimates three types of dispersion:\n\nCommon dispersion: The mean dispersion across all genes.\nTagwise dispersion: A gene-specific dispersion value, accounting for the fact that some genes may have more variability than others.\nTrended dispersion: The mean dispersion across all genes with similar abundance, which can be plotted as a smooth curve showing the relationship between mean expression and dispersion.\n\nThe second step is to fit a quasi-likelihood (QL) negative binomial generalized log-linear model (GLM) to the read counts for each gene with the glmQLFit() function. It also computes a QL dispersion, which reflects the biological variability in counts and the uncertainty in the dispersion estimate, making it more robust to outliers or small sample sizes compared to basic GLMs. It uses empirical Bayes methods to “squeeze” the estimates for genes with unreliable dispersion estimates (e.g. due to low counts) towards the overall trend, resulting in more stable estimates. This provides better control of the false discovery rate (FDR) in RNA-seq data.\nThe third step performs hypothesis testing to determine whether the expression of a gene is significantly different between the experimental groups with the glmQLFTest() function. This uses the QL F-test to produce a test statistic from which a p-value can be computed.\n\n\nCode\ndisp &lt;- estimateDisp(dge_list, design)\nfit &lt;- glmQLFit(disp)\ntt &lt;- glmQLFTest(fit, contrast = contrasts[,\"upf1_vs_control\"]) %&gt;%\n    topTags(n = Inf) %&gt;%\n    .[[\"table\"]] %&gt;%\n    as_tibble() %&gt;%\n    arrange(PValue) %&gt;%\n    dplyr::select(\n        gene_id, gene_name, logFC, logCPM, PValue, FDR, everything()\n    ) %&gt;%\n    mutate(\n        DE = ifelse(FDR &lt; 0.05, TRUE, FALSE),\n        direction = case_when(\n            logFC &lt;= 0 & DE ~ \"Downregulated\",\n            logFC &gt;= 0 & DE ~ \"Upregulated\",\n            !DE ~ \"Non-siginificant\"\n        )\n    )\n\n\nWe now have gene-level assigned p-values, as well as other relevant stats in our tt object. Before we take a look at the results, let’s check some plots to ensure everything looks as expected for RNA-seq data.\nA mean-variance plot can be used to explore the relationship between the mean expression levels of genes and their variance. This helps to assess the assumptions of edgeR’s methodology, which models gene expression using the negative binomial distribution. Here we are looking to evaluate the model fit. If our data points follow the negative binomial line closely, this indicates that the model has effectively captured the mean-variance relationship.\n\n\nCode\nplotMeanVar(\n    disp, show.raw.vars = TRUE, show.tagwise.vars = TRUE, NBline = TRUE\n)\n\n\n\n\n\nMean-variance trend. The black line indicates a typical poisson distribution, while the blue line indicates the negative binomial fit. The grey points indicate raw variances, which are the pooled variances of the counts from each sample, divided by the effective library size. The tagwise variances are indicated as blue points, and the red X’s represent the binned common dispersions.\n\n\n\n\nThe plot clearly illustrates the overdispersion inherent to RNA-seq data. Overall, the data closely follows the fitted negative binomial line, meaning we have established an appropriate model.\nThe dispersion estimates can be viewed in a BCV plot. This allows us to assess data quality by identifying expected (or unexpected) patterns in variability. It also helps to validate the model, confirming the estimated dispersion trends align with the expected relationship between expression and variability.\n\n\nCode\nplotBCV(disp)\n\n\n\n\n\n\n\n\n\nA typical BCV plot shows that variation is higher at low mean expression levels. This is because genes with low counts are more influenced by sampling noise. For very highly expressed genes, the BCV flattens and stabilises, often reaching a minimum value because biological variability dominates over technical noise. The above plot is a great example of what we expect to see from a BCV plot.\nThe QL dispersions are also useful to visualise. It complements the BCV plot by focusing on the uncertainty in both the dispersion and mean-variance relationship.\n\n\nCode\nplotQLDisp(fit)\n\n\n\n\n\n\n\n\n\nA QL dispersion plot can be interpreted similarly to that of a BCV plot. Additionally, we can see how the dispersion estimates are “squeezed” towards the overall trend in variability."
  },
  {
    "objectID": "dge.html#results",
    "href": "dge.html#results",
    "title": "Differential Gene Expression",
    "section": "Results",
    "text": "Results\nThe reactable package is a great package for producing interactive tables in R. It is highly customisable, which also means it can require a reasonable amount of code. However, your collaborators will appreciate nicely formatted results with the ability to easily navigate through the list of genes. In the following code chunk we define some functions that can be re-used to plot reactable tables with less repetition of code.\n\n\nCode\nlb_reactable &lt;- function(\n        tbl, highlight = TRUE, striped = TRUE, compact = TRUE,\n        wrap = FALSE, resizable = TRUE, searchable = TRUE,\n        style = list(fontFamily = \"Calibri, sans-serif\"), ...\n){\n    reactable(\n        tbl,\n        highlight = highlight, striped = striped, compact = compact,\n        wrap = wrap, resizable = TRUE, searchable = TRUE,\n        style = style, ...\n    )\n}\nreact_numeric &lt;- function(format, digits = 2){\n    colDef(cell = function(val, ind, col_name){\n        formatC(val, digits = digits, format = format)\n    })\n}\n\n\nOur tt object holds the results from our DE analysis ordered by p-value, such that the most significant differentially expressed genes exist at the top of the table. We tested 12,329 genes for differential expression, which is a lot. Rendering the entire set of results in our report will impact its file size, so let’s just take the top 1000.\n\n\nCode\n## browsable() allows us to render this html table interactively in RStudio\nbrowsable(\n    ## Use a tagList to include multiple html elements\n    tagList(\n        tags$caption(glue(\n            \"The top 1000 most significant genes \",\n            \"from differential expression analysis. \",\n            \"{sum(tt$DE)} genes were determined to be differentially \",\n            \"expressed (FDR &lt; 0.05).\"\n        )),\n        ## Use our previously defined function to create the table\n        lb_reactable(\n            tt %&gt;%\n                dplyr::slice(1:1000) %&gt;%\n                dplyr::select(\n                    gene_id, gene_name, chromosome = chr,\n                    logFC, logCPM, PValue, FDR, DE\n                ),\n            elementId = \"tt\",\n            defaultColDef = colDef(\n                align = \"left\",\n                minWidth = 80\n            ),\n            ## Numeric column formatting\n            columns = list(\n                logFC = react_numeric(\"f\"),\n                logCPM = react_numeric(\"f\"),\n                PValue = react_numeric(\"e\"),\n                FDR = react_numeric(\"e\")\n            )\n        ),\n        ## Button to download results as CSV file\n        tags$button(\n            tagList(fontawesome::fa(\"download\"), \"Download as CSV\"),\n            onclick = \"Reactable.downloadDataCSV('tt', 'de_results.csv')\"\n        )\n    )\n)\n\n\nThe top 1000 most significant genes from differential expression analysis. 0 genes were determined to be differentially expressed (FDR &lt; 0.05).\n\n\n\n\nDownload as CSV\n\n\n\nIt is usual practice in bioinformatics that a logarithm of base 2 is implied where this information is omitted. Therefore, the logFC and logCPM columns indicate the log2 fold change and counts per million respectively. For example, a gene with logFC = 1 indicates a 2-fold increase in expression in mutant samples relative to controls. Similary, a gene with logCPM = 4 indicates an average expression of 16 CPM across all samples.\nWe classify genes as differentially expressed based on the criteria of a False Discovery Rate (FDR)-adjusted p-value less than 0.05. FDR-adjusted p-values are where raw p-values (PValue column) have been subject to Benjamini-Hochberg correction for multiple hypothesis testing. This is required because we have individually tested the null hypothesis, \\(H_0\\), that there is no differential expression between mutant and control samples for all 12,329 genes in our dataset.\nWe only have 6 genes determined to be differentially expressed in this analysis. This may suggest that the sample groups are not very different. However, in this scenario it is more likely that we are lacking statistical power due to having only 3 samples in the mutant group. 3 samples is the minimum number required to capture biological variability, with at least 5 samples being recommended. Unfortunately, when working with patient data these kind of scenarios are often unavoidable, but we can still make use of our results in downstream analyses, such as Gene Set Enrichment Analysis (GSEA)."
  },
  {
    "objectID": "dge.html#visualising-the-results",
    "href": "dge.html#visualising-the-results",
    "title": "Differential Gene Expression",
    "section": "Visualising the results",
    "text": "Visualising the results\n\nVolcano plot\nVolcano plots are used to visualise the relationship between statistical significance and magnitude of change in gene expression. We plot logFC on the x-axis and -log10(p) on the y-axis, such that the most significant genes are observed at the top of the plot. This helps to identify genes that are both highly significant and exhibit large fold changes. We can also assess the symmetry of the plot to determine in there is an approximately equal number of upregulated and downregulated genes. If an unsymmetrical representation is unexpectedly observed, it may indicate an issue with data quality.\n\n\nCode\ntt %&gt;%\n    bind_rows() %&gt;%\n    arrange(DE) %&gt;%\n    ggplot(aes(logFC, -log10(PValue), colour = direction)) +\n    geom_point(size = 2, alpha = 0.4) +\n    geom_text_repel(\n        aes(label = gene_name),\n        size = 3,\n        data = . %&gt;% dplyr::filter(DE),\n        show.legend = FALSE\n    ) +\n    scale_colour_manual(values = c(\n        \"Upregulated\" = \"darkblue\", \"Downregulated\" = \"darkred\")\n    ) +\n    labs(y = \"-log~10~(*p*)\", colour = \"Direction\") +\n    theme(legend.position = \"none\")\n\n\n\n\n\nVolcano plot from differential expression testing. Upregulated DE genes are coloured blue, downregulated DE genes are coloured red.\n\n\n\n\n\n\nMA plot\nMA plots allow us to visualise the relationship between the magnitude of gene expression change (M) and average expression levels (A). We plot logCPM on the x-axis, and logFC on the y-axis. MA plots are useful for checking whether TMM normalisation has successfully balanced the expression estimates across samples. A properly normalised MA plot should display points mostly centered around y = 0.\n\n\nCode\ntt %&gt;%\n    bind_rows() %&gt;%\n    arrange(DE) %&gt;%\n    ggplot(aes(logCPM, logFC, colour = direction)) +\n    geom_point(size = 2, alpha = 0.4) +\n    geom_text_repel(\n        aes(label = gene_name),\n        size = 3,\n        data = . %&gt;% dplyr::filter(DE),\n        show.legend = FALSE\n    ) +\n    geom_smooth(se = FALSE, colour = \"black\") +\n    scale_colour_manual(values = c(\n        \"Upregulated\" = \"darkblue\", \"Downregulated\" = \"darkred\")\n    ) +\n    labs(colour = \"Direction\") +\n    theme(legend.position = \"none\")\n\n\n\n\n\nMA plot from differential expression testing. Upregulated DE genes are coloured blue, downregulated DE genes are coloured red."
  }
]